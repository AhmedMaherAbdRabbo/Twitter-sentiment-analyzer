{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_Yx337XbScd"
      },
      "source": [
        "## 1. Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2025-08-12T02:48:30.559533Z",
          "iopub.status.busy": "2025-08-12T02:48:30.559259Z",
          "iopub.status.idle": "2025-08-12T02:48:30.565022Z",
          "shell.execute_reply": "2025-08-12T02:48:30.564401Z",
          "shell.execute_reply.started": "2025-08-12T02:48:30.559512Z"
        },
        "id": "EGiI70S8bScf",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import pickle\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVggUi-BbSch"
      },
      "source": [
        "## 2. Download Stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEEWDgPsbSch",
        "outputId": "6130d952-96ba-4df1-fd2b-611f89f06282"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english')) - {'not', 'no', 'never', 'nothing', 'nowhere'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-ZR6NRcbSci"
      },
      "source": [
        "## 3. Data Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2025-08-12T01:56:56.414054Z",
          "iopub.status.busy": "2025-08-12T01:56:56.413764Z",
          "iopub.status.idle": "2025-08-12T01:56:56.825258Z",
          "shell.execute_reply": "2025-08-12T01:56:56.824393Z",
          "shell.execute_reply.started": "2025-08-12T01:56:56.414032Z"
        },
        "id": "b_TbtkYMbSci",
        "outputId": "07a31ba7-773d-483f-aae2-36f22923dacd",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (74682, 4)\n",
            "Test shape: (1000, 4)\n"
          ]
        }
      ],
      "source": [
        "train_data = pd.read_csv('/content/twitter_data/twitter_training.csv', names=['id','entity','sentiment','text'])\n",
        "test_data  = pd.read_csv('/content/twitter_data/twitter_validation.csv', names=['id','entity','sentiment','text'])\n",
        "\n",
        "print(\"Train shape:\", train_data.shape)\n",
        "print(\"Test shape:\", test_data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eFQYNHCjbScj"
      },
      "source": [
        "## 4. Data Cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "z8M196qmbScj"
      },
      "outputs": [],
      "source": [
        "train_data.drop_duplicates(inplace=True)\n",
        "train_data.dropna(subset=['text'], inplace=True)\n",
        "test_data.drop_duplicates(inplace=True)\n",
        "test_data.dropna(subset=['text'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "s9xjB5DJbSck"
      },
      "outputs": [],
      "source": [
        "train_data = train_data[train_data['sentiment'] != 'Irrelevant']\n",
        "test_data = test_data[test_data['sentiment'] != 'Irrelevant']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "-WS7LeBqbSck"
      },
      "outputs": [],
      "source": [
        "positive_words = ['love', 'best', 'amazing', 'great', 'excellent', 'perfect', 'incredible', 'awesome', 'good', 'nice']\n",
        "negative_words = ['hate', 'terrible', 'awful', 'sucks', 'horrible', 'worst', 'bad', 'disgusting', 'broken']\n",
        "\n",
        "def is_misleading_neutral(text):\n",
        "    text_lower = str(text).lower()\n",
        "    return any(w in text_lower for w in positive_words) or any(w in text_lower for w in negative_words)\n",
        "\n",
        "neutral_mask = (train_data['sentiment'] == 'Neutral') & train_data['text'].apply(is_misleading_neutral)\n",
        "train_data = train_data[~neutral_mask]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9V8zC_AGbSck"
      },
      "source": [
        "## 5. Text Preprocessing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "SebfdJRkbScl"
      },
      "outputs": [],
      "source": [
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        text = \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'@[\\w]+', '', text)\n",
        "    text = re.sub(r'https?://\\S+|www\\.\\S+', '', text)\n",
        "    text = re.sub(r'<.*?>', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    words = text.split()\n",
        "    words = [w for w in words if w not in stop_words]\n",
        "    return ' '.join(words)\n",
        "\n",
        "train_data['cleaned_text'] = train_data['text'].apply(clean_text)\n",
        "test_data['cleaned_text'] = test_data['text'].apply(clean_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E2dXvjebScl"
      },
      "source": [
        "## 6. Encode Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE6r6Z2KbScl",
        "outputId": "e45b97d9-106b-4aed-8fcf-a301ecfac503"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Negative': np.int64(0), 'Neutral': np.int64(1), 'Positive': np.int64(2)}\n"
          ]
        }
      ],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "train_data['label'] = label_encoder.fit_transform(train_data['sentiment'])\n",
        "test_data['label'] = label_encoder.transform(test_data['sentiment'])\n",
        "\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ac83sv0XbScl"
      },
      "source": [
        "## 7. Tokenization & Padding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ivM1lEnWbScl"
      },
      "outputs": [],
      "source": [
        "max_words = 10000\n",
        "max_len = 80\n",
        "\n",
        "tokenizer = Tokenizer(num_words=max_words, oov_token=\"<OOV>\")\n",
        "tokenizer.fit_on_texts(train_data['cleaned_text'])\n",
        "\n",
        "X_train = pad_sequences(tokenizer.texts_to_sequences(train_data['cleaned_text']), maxlen=max_len, padding='post')\n",
        "X_test = pad_sequences(tokenizer.texts_to_sequences(test_data['cleaned_text']), maxlen=max_len, padding='post')\n",
        "\n",
        "y_train = to_categorical(train_data['label'], num_classes=3)\n",
        "y_test = to_categorical(test_data['label'], num_classes=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y78CHK0ZbScl"
      },
      "source": [
        "## 8. Build Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "l_bx_JNibScm",
        "outputId": "81f45edc-f92d-405a-a52b-7e39d5845e3f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280,000</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │        <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">10,368</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ embedding_2 (\u001b[38;5;33mEmbedding\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m128\u001b[0m)        │     \u001b[38;5;34m1,280,000\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_4 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │        \u001b[38;5;34m41,216\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ bidirectional_5 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │        \u001b[38;5;34m10,368\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m2,112\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,335,875</span> (5.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,335,875\u001b[0m (5.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,335,875</span> (5.10 MB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,335,875\u001b[0m (5.10 MB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model = Sequential([\n",
        "    Embedding(input_dim=max_words, output_dim=128),\n",
        "    Bidirectional(LSTM(32, return_sequences=True)),\n",
        "    Bidirectional(LSTM(16)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "model.build(input_shape=(None, max_len))\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LknIJ7E6bScm",
        "outputId": "5fe2782d-17f3-4119-aca0-147a2828766a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 29ms/step - accuracy: 0.6150 - loss: 0.8324 - val_accuracy: 0.8640 - val_loss: 0.3504\n",
            "Epoch 2/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 27ms/step - accuracy: 0.8640 - loss: 0.3587 - val_accuracy: 0.9095 - val_loss: 0.2291\n",
            "Epoch 3/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9048 - loss: 0.2417 - val_accuracy: 0.9277 - val_loss: 0.1753\n",
            "Epoch 4/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 31ms/step - accuracy: 0.9228 - loss: 0.1905 - val_accuracy: 0.9386 - val_loss: 0.1394\n",
            "Epoch 5/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 27ms/step - accuracy: 0.9332 - loss: 0.1608 - val_accuracy: 0.9468 - val_loss: 0.1193\n",
            "Epoch 6/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9417 - loss: 0.1358 - val_accuracy: 0.9505 - val_loss: 0.1110\n",
            "Epoch 7/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9468 - loss: 0.1223 - val_accuracy: 0.9538 - val_loss: 0.0978\n",
            "Epoch 8/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9497 - loss: 0.1095 - val_accuracy: 0.9567 - val_loss: 0.0920\n",
            "Epoch 9/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 27ms/step - accuracy: 0.9534 - loss: 0.1017 - val_accuracy: 0.9576 - val_loss: 0.0873\n",
            "Epoch 10/10\n",
            "\u001b[1m868/868\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 27ms/step - accuracy: 0.9555 - loss: 0.0952 - val_accuracy: 0.9612 - val_loss: 0.0829\n"
          ]
        }
      ],
      "source": [
        "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    batch_size=64,\n",
        "    epochs=10,\n",
        "    validation_data=(X_train, y_train,),\n",
        "    callbacks=[early_stop],\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDOA3DFObScm"
      },
      "source": [
        "## 9. Evaluate Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcYPS4AZbScm",
        "outputId": "88d50f94-bb44-435b-8ace-889fc0191c6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9155\n",
            "\u001b[1m26/26\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Negative       0.93      0.97      0.95       266\n",
            "     Neutral       0.96      0.82      0.88       285\n",
            "    Positive       0.87      0.96      0.91       277\n",
            "\n",
            "    accuracy                           0.92       828\n",
            "   macro avg       0.92      0.92      0.92       828\n",
            "weighted avg       0.92      0.92      0.91       828\n",
            "\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f\"Test Accuracy: {acc:.4f}\")\n",
        "\n",
        "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true, y_pred, target_names=label_encoder.classes_))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXswQeBibScm"
      },
      "source": [
        "## 10. Save Model & Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X21fkRAUbScn",
        "outputId": "b8bc845b-6301-48eb-9a8c-1ea6545fb7f9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model and tokenizer saved successfully with accuracy 0.92\n"
          ]
        }
      ],
      "source": [
        "accuracy_score = 0.92\n",
        "model_filename = f\"sentiment_lstm_model_acc_{accuracy_score:.2f}.h5\"\n",
        "tokenizer_filename = f\"tokenizer_acc_{accuracy_score:.2f}.pkl\"\n",
        "label_encoder_filename = f\"label_encoder_acc_{accuracy_score:.2f}.pkl\"\n",
        "\n",
        "model.save(model_filename)\n",
        "\n",
        "with open(tokenizer_filename, 'wb') as f:\n",
        "    pickle.dump(tokenizer, f)\n",
        "\n",
        "with open(label_encoder_filename, 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(f\"Model and tokenizer saved successfully with accuracy {accuracy_score:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D9KFZh8MbScn",
        "outputId": "1bbe86f0-8b34-404f-e616-c9df7598511d",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step\n",
            "Text: I really love this product, it's amazing!\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------\n",
            "Text: The service was terrible and I will never come back\n",
            "Predicted Sentiment: Negative\n",
            "--------------------------------------------------\n",
            "Text: It's okay, nothing special but not bad\n",
            "Predicted Sentiment: Positive\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "sample_texts = [\n",
        "    \"I really love this product, it's amazing!\",\n",
        "    \"The service was terrible and I will never come back\",\n",
        "    \"It's okay, nothing special but not bad\"\n",
        "]\n",
        "\n",
        "sample_cleaned = [clean_text(t) for t in sample_texts]\n",
        "sample_seq = tokenizer.texts_to_sequences(sample_cleaned)\n",
        "sample_pad = pad_sequences(sample_seq, maxlen=max_len, padding='post')\n",
        "\n",
        "predictions = model.predict(sample_pad)\n",
        "predicted_labels = label_encoder.inverse_transform(np.argmax(predictions, axis=1))\n",
        "\n",
        "for i in range(len(sample_texts)):\n",
        "    print(f\"Text: {sample_texts[i]}\")\n",
        "    print(f\"Predicted Sentiment: {predicted_labels[i]}\")\n",
        "    print(\"-\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mK_-QWbymC_H"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 1520310,
          "sourceId": 2510329,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 31089,
      "isGpuEnabled": false,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
